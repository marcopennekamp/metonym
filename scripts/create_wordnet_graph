#!/usr/bin/env python3
from nltk.corpus import wordnet as wn
from argparse import ArgumentParser
import networkx as nx


def add_edges(graph, seen_edges, source, synsets, weight):
    """
    Add a set of edges to the graph coming from a source synset to a set of synsets.

    :param source: The synset that is the source of the edge.
    :param synsets: The synsets that are targeted by the source synset via some relation.
    :param weight: The weight of each edge.
    :return:
    """

    for target in synsets:
        edge = (source.name(), target.name())
        if edge not in seen_edges:
            graph.add_edge(edge[0], edge[1], weight=weight)
            seen_edges.add(edge)
            seen_edges.add((edge[1], edge[0]))


def create_graph():
    seen_edges = set()
    graph = nx.Graph()

    def filter_instances(synsets):
        return filter(lambda s: not s.instance_hypernyms(), synsets)

    # Filter instances right away. We filter a synset if it has at least one instance hypernym,
    # in which case it must be an instance (instances themselves are leafs in the hypernymy tree).
    all_synsets = list(filter_instances(wn.all_synsets()))

    # Add all synsets to the graph. We will add edges later.
    for synset in all_synsets:
        graph.add_node(synset.name())

    # Loop through all synsets and add edges based on the links between two synsets.
    for synset in all_synsets:
        related_synsets = synset.also_sees() + synset.attributes() + \
                          synset.causes() + synset.entailments() + \
                          synset.hypernyms() + synset.hyponyms() + \
                          synset.similar_tos() + synset.topic_domains() + \
                          synset.verb_groups()
        lemmas = synset.lemmas()
        lemma_related = []
        for lemma in lemmas:
            related_lemmas = lemma.derivationally_related_forms() + \
                             lemma.attributes() + lemma.causes() + \
                             lemma.entailments() + lemma.hypernyms() + \
                             lemma.hyponyms() + lemma.similar_tos() + \
                             lemma.topic_domains() + lemma.verb_groups() + \
                             lemma.pertainyms() + lemma.also_sees()
            lemma_related.extend(related_lemmas)
        related_synsets.extend([lemma.synset() for lemma in lemma_related])
        related_synsets = list(filter_instances(set(related_synsets)))
        add_edges(graph, seen_edges, synset, related_synsets, 1)

    print(f'Number of nodes: {graph.number_of_nodes()}')
    print(f'Number of edges: {graph.number_of_edges()}')
    return graph


def main(graph_file):
    graph = create_graph()
    nx.write_gml(graph, graph_file)


if __name__ == "__main__":
    parser = ArgumentParser()
    parser.add_argument("file", help="The output file for the generated wordnet graph")
    args = parser.parse_args()
    if args.file:
        main(args.file)
