#!/usr/bin/env python3
from nltk.corpus import wordnet as wn
from argparse import ArgumentParser
import networkx as nx


def filter_instances(synsets):
    return filter(lambda s: not s.instance_hypernyms(), synsets)


def add_edges(graph, source, synsets, weight):
    """
    Add a set of edges to the graph coming from a source synset to a set of synsets
    or update the weight (the minimum of current and new weight) if an edge is already
    present.

    :param source: The synset that is the source of the edge.
    :param synsets: The synsets that are targeted by the source synset via some relation.
    :param weight: The weight of each edge.
    :return:
    """

    # Filter instance synsets so that instance nodes aren't added by accident.
    filtered_synsets = filter_instances(synsets)
    for target in filtered_synsets:
        u = source.name()
        v = target.name()
        if graph.has_edge(u, v):
            current_weight = graph[u][v]['weight']
            if current_weight > weight:
                graph[u][v]['weight'] = weight
        else:
            graph.add_edge(u, v, weight=weight)


def create_graph():
    graph = nx.Graph()

    # Filter instances right away. We filter a synset if it has at least one instance hypernym,
    # in which case it must be an instance (instances themselves are leafs in the hypernymy tree).
    all_synsets = list(filter_instances(wn.all_synsets()))

    # Add all synsets to the graph. We will add edges later.
    for synset in all_synsets:
        graph.add_node(synset.name())

    # Loop through all synsets and add edges based on the links between two synsets.
    for synset in all_synsets:
        # if synset.pos() == wn.VERB:
        #     weight = 4

        # also_sees: Used to denote similar meanings for adjectives.
        # attributes: Nouns for which adjectives express values (e.g. weight and heavy).
        # causes: Verbs/actions that are caused by the given verb.
        # entailments: Given verb X can't be done unless Y is also done.
        # similar_tos: Adjectives that are similar to the given adjective.
        # topic_domains: Categories that a sense belongs to.
        # verb_groups: Verbs that belong to the same sense group (we should heavily promote this).
        related_synsets = synset.also_sees() + synset.attributes() + \
                          synset.causes() + synset.entailments() + \
                          synset.hypernyms() + synset.hyponyms() + \
                          synset.similar_tos() + synset.topic_domains() + \
                          synset.verb_groups()
        lemmas = synset.lemmas()
        lemma_related = []
        for lemma in lemmas:
            related_lemmas = lemma.derivationally_related_forms() + \
                             lemma.attributes() + lemma.causes() + \
                             lemma.entailments() + lemma.hypernyms() + \
                             lemma.hyponyms() + lemma.similar_tos() + \
                             lemma.topic_domains() + lemma.verb_groups() + \
                             lemma.pertainyms() + lemma.also_sees()
            lemma_related.extend(related_lemmas)
        related_synsets.extend([lemma.synset() for lemma in lemma_related])
        related_synsets = list(set(related_synsets))
        add_edges(graph, synset, related_synsets, 1)

    print(f'Number of nodes: {graph.number_of_nodes()}')
    print(f'Number of edges: {graph.number_of_edges()}')
    return graph


def main(graph_file):
    graph = create_graph()
    nx.write_gml(graph, graph_file)


if __name__ == "__main__":
    parser = ArgumentParser()
    parser.add_argument("file", help="The output file for the generated wordnet graph")
    args = parser.parse_args()
    if args.file:
        main(args.file)
